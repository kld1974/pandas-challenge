{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyCity Schools Analysis\n",
    "\n",
    "* As a whole, schools with higher budgets, did not yield better test results. By contrast, schools with higher spending 645-675 per student actually underperformed compared to schools with smaller budgets (585 per student).\n",
    "\n",
    "* As a whole, smaller and medium sized schools dramatically out-performed large sized schools on passing math performances (89-91% passing vs 67%).\n",
    "\n",
    "* As a whole, charter schools out-performed the public district schools across all metrics. However, more analysis will be required to glean if the effect is due to school practices or the fact that charter schools tend to serve smaller student populations per school. \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'PyCitySchools/Resources/schools_complete.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Read School and Student Data File and store into Pandas DataFrames\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m school_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mPyCitySchools/Resources/schools_complete.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/RUTDataViz2023/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/RUTDataViz2023/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/RUTDataViz2023/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/RUTDataViz2023/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/RUTDataViz2023/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/RUTDataViz2023/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/RUTDataViz2023/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PyCitySchools/Resources/schools_complete.csv'"
     ]
    }
   ],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "\n",
    "# Read School and Student Data File and store into Pandas DataFrames\n",
    "school_data = pd.read_csv(\"PyCitySchools/Resources/schools_complete.csv\")\n",
    "student_data = pd.read_csv(\"PyCitySchools/Resources/students_complete.csv\")\n",
    "\n",
    "#school_data\n",
    "\n",
    "# Combine the data into a single dataset.  \n",
    "#school_data_complete = pd.merge(student_data, school_data, how=\"left\", on=[\"school_name\", \"school_name\"])\n",
    "#school_data_complete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## District Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1212100793.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    school_count =\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of unique schools\n",
    "school_count = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of students\n",
    "student_count = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total budget\n",
    "total_budget = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average (mean) math score\n",
    "average_math_score = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average (mean) reading score\n",
    "average_reading_score = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following to calculate the percentage of students who passed math (math scores greather than or equal to 70)\n",
    "passing_math_count = school_data_complete[(school_data_complete[\"math_score\"] >= 70)].count()[\"student_name\"]\n",
    "passing_math_percentage = passing_math_count / float(student_count) * 100\n",
    "passing_math_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of students who passeed reading (hint: look at how the math percentage was calculated)  \n",
    "passing_reading_count = \n",
    "passing_reading_percentage = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following to calculate the percentage of students that passed math and reading\n",
    "passing_math_reading_count = school_data_complete[\n",
    "    (school_data_complete[\"math_score\"] >= 70) & (school_data_complete[\"reading_score\"] >= 70)\n",
    "].count()[\"student_name\"]\n",
    "overall_passing_rate = passing_math_reading_count /  float(student_count) * 100\n",
    "overall_passing_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a high-level snapshot of the district's key metrics in a DataFrame\n",
    "district_summary = \n",
    "\n",
    "# Formatting\n",
    "district_summary[\"Total Students\"] = district_summary[\"Total Students\"].map(\"{:,}\".format)\n",
    "district_summary[\"Total Budget\"] = district_summary[\"Total Budget\"].map(\"${:,.2f}\".format)\n",
    "\n",
    "# Display the DataFrame\n",
    "district_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## School Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the code provided to select the school type\n",
    "school_types = school_data.set_index([\"school_name\"])[\"type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total student count\n",
    "per_school_counts = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total school budget and per capita spending\n",
    "per_school_budget = school_data_complete.groupby([\"school_name\"]).mean()[\"budget\"]\n",
    "per_school_capita = per_school_budget / per_school_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average test scores\n",
    "per_school_math = \n",
    "per_school_reading = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of schools with math scores of 70 or higher\n",
    "school_passing_math = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of schools with reading scores of 70 or higher\n",
    "school_passing_reading = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the provided code to calculate the schools that passed both math and reading with scores of 70 or higher\n",
    "passing_math_and_reading = school_data_complete[\n",
    "    (school_data_complete[\"reading_score\"] >= 70) & (school_data_complete[\"math_score\"] >= 70)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the provided code to calculate the passing rates\n",
    "per_school_passing_math = school_passing_math.groupby([\"school_name\"]).count()[\"student_name\"] / per_school_counts * 100\n",
    "per_school_passing_reading = school_passing_reading.groupby([\"school_name\"]).count()[\"student_name\"] / per_school_counts * 100\n",
    "overall_passing_rate = passing_math_and_reading.groupby([\"school_name\"]).count()[\"student_name\"] / per_school_counts * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame called `per_school_summary` with columns for the calculations above.\n",
    "\n",
    "\n",
    "# Formatting\n",
    "per_school_summary[\"Total School Budget\"] = per_school_summary[\"Total School Budget\"].map(\"${:,.2f}\".format)\n",
    "per_school_summary[\"Per Student Budget\"] = per_school_summary[\"Per Student Budget\"].map(\"${:,.2f}\".format)\n",
    "\n",
    "# Display the DataFrame\n",
    "per_school_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest-Performing Schools (by % Overall Passing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort the schools by `% Overall Passing` in descending order and display the top 5 rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottom Performing Schools (By % Overall Passing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the schools by `% Overall Passing` in ascending order and display the top 5 rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math Scores by Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the code provided to separate the data by grade\n",
    "ninth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"9th\")]\n",
    "tenth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"10th\")]\n",
    "eleventh_graders = school_data_complete[(school_data_complete[\"grade\"] == \"11th\")]\n",
    "twelfth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"12th\")]\n",
    "\n",
    "# Group by \"school_name\" and take the mean of each.\n",
    "ninth_graders_scores = \n",
    "tenth_graders_scores = \n",
    "eleventh_graders_scores = \n",
    "twelfth_graders_scores = \n",
    "\n",
    "# Use the code to select only the `math_score`.\n",
    "ninth_grade_math_scores = ninth_graders_scores[\"math_score\"]\n",
    "tenth_grader_math_scores = tenth_graders_scores[\"math_score\"]\n",
    "eleventh_grader_math_scores = eleventh_graders_scores.mean()[\"math_score\"]\n",
    "twelfth_grader_math_scores = twelfth_graders_scores[\"math_score\"]\n",
    "\n",
    "# Combine each of the scores above into single DataFrame called `math_scores_by_grade`\n",
    "\n",
    "\n",
    "# Minor data wrangling\n",
    "math_scores_by_grade.index.name = None\n",
    "\n",
    "# Display the DataFrame\n",
    "math_scores_by_grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Score by Grade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the code provided to separate the data by grade\n",
    "ninth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"9th\")]\n",
    "tenth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"10th\")]\n",
    "eleventh_graders = school_data_complete[(school_data_complete[\"grade\"] == \"11th\")]\n",
    "twelfth_graders = school_data_complete[(school_data_complete[\"grade\"] == \"12th\")]\n",
    "\n",
    "# Group by \"school_name\" and take the mean of each.\n",
    "ninth_graders_scores = \n",
    "tenth_graders_scores = \n",
    "eleventh_graders_scores = \n",
    "twelfth_graders_scores = \n",
    "\n",
    "# Use the code to select only the `reading_score`.\n",
    "ninth_grade_reading_scores = ninth_graders_scores[\"reading_score\"]\n",
    "tenth_grader_reading_scores = tenth_graders_scores[\"reading_score\"]\n",
    "eleventh_grader_reading_scores = eleventh_graders_scores.mean()[\"reading_score\"]\n",
    "twelfth_grader_reading_scores = twelfth_graders_scores[\"reading_score\"]\n",
    "\n",
    "# Combine each of the scores above into single DataFrame called `reading_scores_by_grade`\n",
    "\n",
    "\n",
    "# Minor data wrangling\n",
    "reading_scores_by_grade = reading_scores_by_grade[[\"9th\", \"10th\", \"11th\", \"12th\"]]\n",
    "reading_scores_by_grade.index.name = None\n",
    "\n",
    "# Display the DataFrame\n",
    "reading_scores_by_grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores by School Spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the bins \n",
    "spending_bins = [0, 585, 630, 645, 680]\n",
    "labels = [\"<$585\", \"$585-630\", \"$630-645\", \"$645-680\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the school summary since it has the \"Per Student Budget\" \n",
    "school_spending_df = per_school_summary.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `pd.cut` to categorize spending based on the bins.\n",
    "school_spending_df[\"Spending Ranges (Per Student)\"] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Calculate averages for the desired columns. \n",
    "spending_math_scores = school_spending_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Math Score\"]\n",
    "spending_reading_scores = school_spending_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"Average Reading Score\"]\n",
    "spending_passing_math = school_spending_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Math\"]\n",
    "spending_passing_reading = school_spending_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Passing Reading\"]\n",
    "overall_passing_spending = school_spending_df.groupby([\"Spending Ranges (Per Student)\"]).mean()[\"% Overall Passing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble into DataFrame\n",
    "spending_summary = \n",
    "\n",
    "# Display results\n",
    "spending_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores by School Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish the bins.\n",
    "size_bins = [0, 1000, 2000, 5000]\n",
    "labels = [\"Small (<1000)\", \"Medium (1000-2000)\", \"Large (2000-5000)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize the spending based on the bins\n",
    "# Use `pd.cut` on the \"Total Students\" column of the `per_school_summary` DataFrame.\n",
    "\n",
    "per_school_summary[\"School Size\"] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages for the desired columns. \n",
    "size_math_scores = per_school_summary.groupby([\"School Size\"]).mean()[\"Average Math Score\"]\n",
    "size_reading_scores = per_school_summary.groupby([\"School Size\"]).mean()[\"Average Reading Score\"]\n",
    "size_passing_math = per_school_summary.groupby([\"School Size\"]).mean()[\"% Passing Math\"]\n",
    "size_passing_reading = per_school_summary.groupby([\"School Size\"]).mean()[\"% Passing Reading\"]\n",
    "size_overall_passing = per_school_summary.groupby([\"School Size\"]).mean()[\"% Overall Passing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame called `size_summary` that breaks down school performance based on school size (small, medium, or large).\n",
    "# Use the scores above to create a new DataFrame called `size_summary`\n",
    "\n",
    "\n",
    "# Display results\n",
    "size_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores by School Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the per_school_summary DataFrame by \"School Type\" and average the results.\n",
    "type_math_scores = \n",
    "type_reading_scores = \n",
    "type_passing_math = \n",
    "type_passing_reading = \n",
    "type_overall_passing = \n",
    "\n",
    "# Use the code provided to select new column data\n",
    "average_math_score_by_type = type_math_scores[\"Average Math Score\"]\n",
    "average_reading_score_by_type = type_reading_scores[\"Average Reading Score\"]\n",
    "average_percent_passing_math_by_type = type_passing_math[\"% Passing Math\"]\n",
    "average_percent_passing_reading_by_type = type_passing_reading[\"% Passing Reading\"]\n",
    "average_percent_overall_passing_by_type = type_overall_passing[\"% Overall Passing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the new data by type into a DataFrame called `type_summary`\n",
    "\n",
    "\n",
    "# Display results\n",
    "type_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nteract": {
   "version": "0.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
